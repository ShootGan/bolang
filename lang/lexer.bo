module lexer

imports ../std/io
imports ../std/strings
imports ../std/chars

type Token {null | TokOp:String | TokInt:i64 | TokIdent:String | TokKeyword:String }

let keywords  = ["let", "while", "fn", "true", "false", "null", "if", "else"]
let operators = ["+", "-", "*", "/", "%", "=", "+=", "-=", "*=", "/=", "%="]

fn parseStr(word String, str String) (String, String)
    let i = 0
    while true
        switch i
            _ | i >= len(word)    ; return (str[..i], str[i..])
            _ | i >= len(str)     ; return ([], str)
            _ | word[i] != str[i] ; return ([], str)
            _                     ; i = i + 1


fn parseKeyword(str String) (Token, String)
    let i = 0
    while i < len(keywords)
        switch parseStr(String(keywords[i]), str)
            ([], _)   ; i = i + 1
            (s, rest) ; return (TokKeyword(&String(s)), rest)

    return (null, str)


fn parseIdent(str String) (Token, String)
    let i = 0

    if i >= len(str) || !isAlpha(str[i])
        return (null, str)

    while i < len(str) && (isDigit(str[i]) || isAlpha(str[i]))
        i = i + 1

    return (TokIdent(&str[..i]), str[i..])


fn parseOperator(str String) (Token, String)
    let i = 0
    let (j, max) = (0, 0)

    while i < len(operators)
        let s = String(operators[i])
        if isPrefix(s, str) && len(s) > max
            max = len(s)
            j = i
        i = i + 1
    
    if max > 0
        return (TokOp(&String(operators[j])),  str[max..])
    return (null, str)


fn parseWhite(str String) String
    let i = 0
    while i < len(str) && (str[i] == ' ' || str[i] == '\t')
        i = i + 1

    return str[i..]


fn parseToken(str String) (Token, String)
    switch parseKeyword(str)
        (null, _) ;
        (tok, ss) ; return (tok, parseWhite(ss))

    switch parseIdent(str)
        (null, _) ;
        (tok, ss) ; return (tok, parseWhite(ss))

    switch parseOperator(str)
        (null, _) ;
        (tok, ss) ; return (tok, parseWhite(ss))

    return (null, str)




            
    
