module lexer

import ../std/io
import ../std/strings
import ../std/chars

type Token {
    null
    TokOp      : string
    TokInt     : i64
    TokSym     : char
    TokIdent   : string
    TokString  : string
    TokChar    : char
    TokKeyword : string
}

fn string(token Token) string
    switch token 
        null         ; return "null"
        TokOp(s)     ; return "TokOp: " + s
        TokInt(n)    ; return "TokInt: " + string(n)
        TokSym(c)    ; return "TokSym: " + [c]
        TokString(s) ; return "TokString: " + s
        TokChar(c)   ; return "TokChar: " + [c]
        TokIdent(s)  ; return "TokIdent: " + s
        TokKeyword(s); return "TokKeyword: " + s

fn ==(a Token, b Token) bool
    switch (a, b)
        (null, null); return true
        (TokOp(a), TokOp(b)) | a == b          ; return true
        (TokInt(a), TokInt(b)) | a == b        ; return true
        (TokSym(a), TokSym(b)) | a == b        ; return true
        (TokIdent(a), TokIdent(b)) | a == b    ; return true
        (TokString(a), TokString(b)) | a == b  ; return true
        (TokChar(a), TokChar(b)) | a == b      ; return true
        (TokKeyword(a), TokKeyword(b)) | a == b; return true
        _                                      ; return false



let keywords  = ["let", "while", "fn", "extern", "true", "false", "null", "if", "else", "return", "module", "imports", "append"]
let types     = ["i8", "i16", "i32", "i64", "char", "bool", "string"]
let operators = ["+", "-", "*", "/", "%", "=", "+=", "-=", "*=", "/=", "%=", "..", "<", ">", "<=", ">=", "&&", "||", "=="]
let symbols   = ['(', ')', '[', ']', '{', '}', ':', ';', '.', ',']

fn lexChar(str string) (Token, string)
    switch str
        "'\\n'" .. ss        ; return (TokChar('\n'), ss)
        "'\\0'" .. ss        ; return (TokChar('\0'), ss)
        "'\\t'" .. ss        ; return (TokChar('\t'), ss)
        "'\\'" .. ss         ; return (TokChar('\\'), ss)
        "'\n" .. ss          ; return (null, str)
        "'\t" .. ss          ; return (null, str)
        ['\'', c, '\''] .. ss; return (TokChar(c), ss)
        _                    ; return (null, str)


fn lexString(str string) (Token, string)
    if !strIsPrefix("\"", str)
        return (null, str)

    let s = ""
    let rest = str[1..]

    while true
        switch rest
            "\n"  .. ss; return (null, str)
            "\\n" .. ss
                s = s + "\n"
                rest = ss
            "\\0" .. ss
                s = s + "\0"
                rest = ss
            "\\t" .. ss
                s = s + "\t"
                rest = ss
            "\"" .. ss
                return (TokString(s), ss)
            [c] .. ss
                s = s + [c]
                rest = ss


fn lexSymbol(str string) (Token, string)
    switch str
        [c] .. s
            let i = 0
            while i < len(symbols)
                if c == symbols[i]
                    return (TokSym(c), s)
                i = i + 1
        _; return (null, str)


fn lexKeyword(str string) (Token, string)
    let (i, k) = (0, 0)

    while str[i..] -> [c] .. | isAlpha(c)
        i = i + 1

    let word = str[..i]
    while k < len(keywords)
        if word == keywords[k]
            return (TokKeyword(word), str[i..])
        k = k + 1

    return (null, str)

fn lexDigits(str string) (Token, string)
    let i = 0
    while str[i..] -> [c] .. | isDigit(c)
        i = i + 1
 
    switch strReadInt(str[..i])
        (n, true) ; return (TokInt(n), str[i..])
        (_, false); return (null, str)


fn lexIdent(str string) (Token, string)
    if str -> [c] .. | isAlpha(c)
        let i = 0
        while str[i..] -> [c] .. | isAlpha(c) || isDigit(c)
            i = i + 1
        return (TokIdent(str[..i]), str[i..])

    return (null, str)


fn lexOperator(str string) (Token, string)
    let (i, j, max) = (0, 0, 0)

    while i < len(operators)
        if strIsPrefix(operators[i], str) && len(operators[i]) > max
            max = len(operators[i])
            j = i
        i = i + 1
    
    switch max
        0; return (null, str)
        n; return (TokOp(operators[j]),  str[n..])


fn lexWhite(str string) string
    let i = 0

    while true
        switch str[i]
            ' ' ;
            '\t';
            '\n';
            _   ; return str[..i]
        i = i + 1


fn lexToken(str string) (Token, string)
    if lexWhite(str) -> s | len(s) > 0
        return lexToken(str[len(s)..])

    switch lexKeyword(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexString(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexChar(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexIdent(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexOperator(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexDigits(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexSymbol(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    return (null, str)

fn lexTokens(str string) ([Token], string)
    let toks = :[Token]()
    let loop = true
    while loop
        switch lexToken(str)
            (null, _); return (toks, str)
            (tok, ss)
                str = ss
                toks <- tok
