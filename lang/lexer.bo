module lexer

imports ../std/io
imports ../std/strings
imports ../std/chars

type TokSym   String
type TokIdent String
type TokInt   i64

type Token {null, TokSym, TokInt, TokIdent}


let keywords = ["let", "while", "fn", "true", "false", "null", "if", "else"]

fn parseStr(word String, str String) (:Token, :String)
    let i = 0
    while true
        switch i
            _ | i >= len(word)    : return (Token(&TokSym(str[..i])), str[i..])
            _ | i >= len(str)     : return (null, str)
            _ | word[i] != str[i] : return (null, str)
            _                     : i = i + 1


fn parseKeyword(str String) (:Token, :String)
    let i = 0
    while i < len(keywords)
        switch parseStr(String(keywords[i]), str)
            (null, _)   : i = i + 1
            (tok, rest) : return (tok, rest)

    return (null, str)


fn parseIdent(str String) (:Token, :String)
    let i = 0

    if i >= len(str) || !isAlpha(str[i])
        return (null, str)

    while i < len(str) && (isDigit(str[i]) || isAlpha(str[i]))
        i = i + 1

    return (Token(&TokIdent(str[..i])), str[i..])




            
    
