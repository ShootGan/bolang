module lexer

imports ../std/io
imports ../std/strings
imports ../std/chars

type Token {
    null
    TokOp      string
    TokInt     i64
    TokSym     char
    TokIdent   string
    TokString  string
    TokChar    char
    TokKeyword string
}

let keywords  = ["let", "while", "fn", "extern", "true", "false", "null", "if", "else", "return", "module", "imports", "append"]
let types     = ["i8", "i16", "i32", "i64", "char", "bool", "string"]
let operators = ["+", "-", "*", "/", "%", "=", "+=", "-=", "*=", "/=", "%=", "..", "<", ">", "<=", ">=", "&&", "||", "=="]
let symbols   = ['(', ')', '[', ']', '{', '}', ':', ';', '.', ',']

fn lexChar(str string) (Token, string)
    switch str
        "'\\n'" .. ss          ; return (TokChar('\n'), ss)
        "'\\0'" .. ss          ; return (TokChar('\0'), ss)
        "'\\t'" .. ss          ; return (TokChar('\t'), ss)
        "'\\'" .. ss           ; return (TokChar('\\'), ss)
        "'\n" .. ss            ; return (null, str)
        "'\t" .. ss            ; return (null, str)
        "'" .. [c] .. "'" .. ss; return (TokChar(c), ss)
        _;
    return (null, str)


fn lexString(str string) (Token, string)
    if !strIsPrefix("\"", str)
        return (null, str)

    let s = ""
    let rest = str[1..]

    while true
        switch rest
            "\n"  .. ss; return (null, str)
            "\\n" .. ss
                s = append(s, "\n")
                rest = ss
            "\\0" .. ss
                s = append(s, "\0")
                rest = ss
            "\\t" .. ss
                s = append(s, "\t")
                rest = ss
            "\"" .. ss
                return (TokString(s), ss)
            [c] .. ss
                s = append(s, [c])
                rest = ss


fn lexSymbol(str string) (Token, string)
    switch str
        [c] .. s
            let i = 0
            while i < len(symbols)
                if c == symbols[i]
                    return (TokSym(c), s)
                i = i + 1
        _; return (null, str)


fn lexKeyword(str string) (Token, string)
    let (i, k) = (0, 0)

    while str[i..] -> [c] .. | isAlpha(c)
        i = i + 1

    let word = str[..i]
    while k < len(keywords)
        if word == keywords[k]
            return (TokKeyword(word), str[i..])
        k = k + 1

    return (null, str)

fn lexDigits(str string) (Token, string)
    let i = 0
    while str[i..] -> [c] .. | isDigit(c)
        i = i + 1
 
    switch strReadInt(str[..i])
        i64(n); return (TokInt(n), str[i..])
        null  ; return (null, str)


fn lexIdent(str string) (Token, string)
    if str -> [c] .. | isAlpha(c)
        let i = 0
        while str[i..] -> [c] .. | isAlpha(c) || isDigit(c)
            i = i + 1
        return (TokIdent(str[..i]), str[i..])

    return (null, str)


fn lexOperator(str string) (Token, string)
    let (i, j, max) = (0, 0, 0)

    while i < len(operators)
        if strIsPrefix(operators[i], str) && len(operators[i]) > max
            max = len(operators[i])
            j = i
        i = i + 1
    
    switch max
        0; return (null, str)
        n; return (TokOp(operators[j]),  str[n..])


fn lexWhite(str string) string
    let i = 0

    while true
        switch str[i]
            ' ' ;
            '\t';
            '\n';
            _   ; return str[..i]
        i = i + 1


fn lexToken(str string) (Token, string)
    if lexWhite(str) -> s | len(s) > 0
        return lexToken(str[len(s)..])

    switch lexKeyword(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexString(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexChar(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexIdent(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexOperator(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexDigits(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    switch lexSymbol(str)
        (null, _) ;
        (tok, ss) ; return (tok, ss)

    return (null, str)
