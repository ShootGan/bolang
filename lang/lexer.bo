module lexer

imports ../std/io
imports ../std/strings
imports ../std/chars

type Token {null | TokInt:i64 | TokIdent:String | TokKeyword:String }

let keywords = ["let", "while", "fn", "true", "false", "null", "if", "else"]

fn parseStr(word String, str String) (:String, :String)
    let i = 0
    while true
        switch i
            _ | i >= len(word)    ; return (str[..i], str[i..])
            _ | i >= len(str)     ; return ([], str)
            _ | word[i] != str[i] ; return ([], str)
            _                     ; i = i + 1


fn parseKeyword(str String) (:Token, :String)
    let i = 0
    while i < len(keywords)
        switch parseStr(String(keywords[i]), str)
            ([], _)   ; i = i + 1
            (s, rest) ; return (TokKeyword(&String(s)), rest)

    return (null, str)


fn parseIdent(str String) (:Token, :String)
    let i = 0

    if i >= len(str) || !isAlpha(str[i])
        return (null, str)

    while i < len(str) && (isDigit(str[i]) || isAlpha(str[i]))
        i = i + 1

    return (TokIdent(&str[..i]), str[i..])




            
    
